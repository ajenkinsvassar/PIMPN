{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PIMPIN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/etterguillaume/PIMPN/blob/master/PIMPIN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "8YYFduPQ1mCI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **PIMPN (Python Integrated Miniscope Pipeline Notebook)**\n",
        "\n",
        "**Version: 0.8.1**\n",
        "\n",
        "This Colab Notebook has been designed to analyze calcium imaging and behavior videos directly on the cloud. It relies on a Dropbox API, CaImAn, which itself uses NormCorre for motion correction as well as Constrained Non-Negative Matrix Factorization (CNMF/CNMFE) for source extraction. Behavior video can be analyzed automatically using DeepLabCut and your own DeepPose model (currently working on making pre-trained models available).\n",
        "\n",
        "# Features\n",
        "- **Fully automatic and unsupervised:** once you found parameters that work well for your conditions, and trained deep learning models that suit your data (pre-trained models also available), you can run your analyzes in one click\n",
        "- **Tailored for miniscope data**: Registers miniscope timestamps and informations about your experiment (subject name, date of experiment), dedicated to multiple .avi files although works with other formats (hdf5, tiff).\n",
        "- **Cloud based**: Google Colab will temporarily allocate a virtual machine to perform the analysis job. No need to download data on your local computer, and save computing for other tasks! Analyzed data is transfered back to your cloud server.\n",
        "- **Compatibility:** the data generated by the analysis can be saved in a matlab file that is compatible with [MiniscopeAnalysis](https://github.com/etterguillaume/MiniscopeAnalysis), but also hdf5 files that can be organized the way you like.\n",
        "\n",
        "**DISCLAIMER**\n",
        "PIMPIN relies on a powerful Dropbox API that allows to interact with your cloud repositories (dowload, upload, list or remove files). While it is design to facilitate access, downloads and uploads, beware of misuses. If you plan on sharing this notebook, do not forget to remove your Dropbox access token unless you wish to grant access to your data. You can also enter your gmail credentials to get notified when your analysis is done. Here again, don't forget to remove this info when sharing the notebook.\n",
        "\n",
        "Copyright Â© Guillaume Etter 2019\n",
        "\n",
        "This program is free software; you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation; either version 3 of the License, or any later version.\n",
        "\n",
        "Contact: etterguillaume@gmail.com"
      ]
    },
    {
      "metadata": {
        "id": "wsXpNPZz94zc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Get informations about the virtual machine being used"
      ]
    },
    {
      "metadata": {
        "id": "bInwkvBy9354",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Disk information\n",
        "!df -h\n",
        "# CPU information\n",
        "!lscpu | grep \"MHz\"\n",
        "# If using a GPU\n",
        "!nvidia-smi -L\n",
        "!nvcc --version\n",
        "# Memory information\n",
        "!cat /proc/meminfo | grep 'MemAvailable'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r-Azck7r_L4K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Parameters"
      ]
    },
    {
      "metadata": {
        "id": "NM-o_oY_3v9M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "access_token = '' # Get your access token from https://www.dropbox.com/developers/apps\n",
        "path_to_analyze = ''\n",
        "analyze_behavior = True\n",
        "path_to_DLC_model = '' # Change yours here. Should be a zip file containing your full, trained model\n",
        "spatial_downsampling = 3 # Drastically speeds up processing. 2-3 recommended\n",
        "isnonrigid = False\n",
        "path_to_results = '' # Where to save the data\n",
        "alert_gmail = '' # You can leave your Gmail adress to be notified when your analysis is done\n",
        "alert_gmail_password = '' # Password to your Gmail account\n",
        "\n",
        "print('Parameters saved. Ready to start analyzing')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aEkX5SCRnD_M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Install and import dependencies"
      ]
    },
    {
      "metadata": {
        "id": "LU1TeIPrBLx_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import scipy.io as sio\n",
        "import re\n",
        "import os\n",
        "import h5py\n",
        "import csv\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import logging\n",
        "import zipfile\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "mpl.style.use('default')\n",
        "import numpy as np\n",
        "from moviepy.editor import *\n",
        "import smtplib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LgzbkNnLA8Fa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Install Dropbox\n",
        "!pip install dropbox\n",
        "import dropbox"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JQtbmwfsnBPV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Install CaImAn\n",
        "#!git clone https://github.com/flatironinstitute/CaImAn.git\n",
        "!git clone https://github.com/etterguillaume/CaImAn.git\n",
        "%cd '/content/CaImAn/'\n",
        "!pip install -e .\n",
        "\n",
        "!pip install tifffile\n",
        "!pip install ipyparallel\n",
        "!pip install peakutils\n",
        "\n",
        "%cd '/content/CaImAn/'\n",
        "!python caimanmanager.py install --inplace\n",
        "\n",
        "!export MKL_NUM_THREADS=1\n",
        "!export OPENBLAS_NUM_THREADS=1\n",
        "\n",
        "# This is for GPU accelaration\n",
        "!pip install pycuda\n",
        "!pip install scikit-cuda\n",
        "\n",
        "import caiman as cm\n",
        "from caiman.source_extraction import cnmf\n",
        "from caiman.utils.visualization import inspect_correlation_pnr\n",
        "from caiman.motion_correction import MotionCorrect\n",
        "from caiman.source_extraction.cnmf import params as params\n",
        "import peakutils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q3SSJjBk02Tf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Access DropBox\n",
        "This creates a dbx Dropbox object. It necessitates that you enter a valid token earlier while setting up parameters"
      ]
    },
    {
      "metadata": {
        "id": "y1OlilXu0ySW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dbx = dropbox.Dropbox(access_token)\n",
        "print('Connected to Dropbox')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pdgiWMUC93aZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Get information from the experiment\n",
        "This is particularily important to register the date/time and name of the experiment, which are also use to create specific analysis folders containing all the analyzed data (calcium imaging and behavior). Additionnaly, timestamps are retrieved and allow to realign calcium imaging with behavior videos"
      ]
    },
    {
      "metadata": {
        "id": "s56U7SjB92wF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "now = datetime.now()\n",
        "analysis_time = now.strftime(\"%Y-%m-%d %H:%M\") # This is to register when the analysis was performed\n",
        "print('Analysis started on ' + analysis_time)\n",
        "\n",
        "analysis_start = time.time() # This is to register the time spent analyzing\n",
        "\n",
        "# Open dat file here \n",
        "try:\n",
        "  metadata, res = dbx.files_download(path_to_analyze + '/' + 'settings_and_notes.dat')\n",
        "  f = open('settings_and_notes.dat','wb')\n",
        "  f.write(res.content)\n",
        "  f.close\n",
        "except FileExistsError:\n",
        "  print('Error: settings_and_notes.dat could not be found')\n",
        "\n",
        "with open('settings_and_notes.dat') as f:\n",
        "  for i, line in enumerate(f):\n",
        "    if i == 0:\n",
        "      line = str(f.readline())\n",
        "      line = line.split('\\t')\n",
        "      experimentName = line[0]\n",
        "      \n",
        "print('Name of the experiment to analyze: ' + experimentName)\n",
        "\n",
        "dirExperimentName = '/content/' + experimentName\n",
        " \n",
        "try:\n",
        "    # Create target Directory\n",
        "    os.mkdir(dirExperimentName)\n",
        "    print(\"Directory \" , dirExperimentName ,  \" Created\") \n",
        "except FileExistsError:\n",
        "    print(\"Directory \" , dirExperimentName ,  \" already exists\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mRTHs8iX8ofY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Extract the date/time of the experiment and save as a timestamp variable\n",
        "The date/time values are extracted from the automatic DAQ folder organization (might not work if you renamed your folders)"
      ]
    },
    {
      "metadata": {
        "id": "vVw4iBFHoeNq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "try:\n",
        "  from datetime import datetime\n",
        "  splitname = str.split(path_to_analyze, '/')\n",
        "\n",
        "  dateStrPart = splitname[-2]\n",
        "  timeStrPart = splitname[-1]\n",
        "\n",
        "  date_result = str.split(dateStrPart, '_')\n",
        "  month = int(date_result[0])\n",
        "  day = int(date_result[1])\n",
        "  year = int(date_result[2])\n",
        "\n",
        "  timeStrPart = re.sub('[HSM]','', timeStrPart)\n",
        "  time_result = str.split(timeStrPart,'_')\n",
        "  \n",
        "  hour = int(time_result[0])\n",
        "  minute = int(time_result[1])\n",
        "  seconds = int(time_result[2])\n",
        "  \n",
        "  experiment_timestamp = datetime.timestamp(datetime(year,month,day,hour,minute,seconds))\n",
        "  #dateNum = date.toordinal(date(year,month,day,hour,minute,seconds))\n",
        "\n",
        "except:\n",
        "  print('Could not retrieve date information')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CdwNbqxt2bIi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Access Dropbox and download miniscope video files\n"
      ]
    },
    {
      "metadata": {
        "id": "pzi0XewMFzlb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sessionFilesResponse = dbx.files_list_folder(path_to_analyze)\n",
        "filesList = []\n",
        "msFileList = []\n",
        "\n",
        "for file in sessionFilesResponse.entries:\n",
        "  filesList.append(file.name)\n",
        "\n",
        "for i in filesList[:]:\n",
        "  if i.startswith('ms') and i.endswith('.avi'):\n",
        "    msFileList.append(i)\n",
        "    \n",
        "msFileList = sorted(msFileList, key=lambda x: int(re.sub('[msCam.avi]','', x)))\n",
        "\n",
        "# FOR Quick BETA TESTING\n",
        "#msFileList = msFileList[0:2]\n",
        "\n",
        "print('Miniscope files in folder:')\n",
        "print(msFileList)\n",
        "\n",
        "if len(msFileList) == 0:\n",
        "  print(\"No miniscope avi files found\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "967_uAR82Ng_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('Downloading miniscope videos from Dropbox.....')\n",
        "for file in msFileList:\n",
        "    f = open(dirExperimentName + '/' + file,\"wb+\") \n",
        "    metadata, res = dbx.files_download(path_to_analyze + '/' + file)\n",
        "    f.write(res.content)\n",
        "    f.close()\n",
        "    print(path_to_analyze + '/' + file + '.....done!')\n",
        "print('Done downloading miniscope videos!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LL2q6Va5nneN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create a list of files downloaded on the Colab virtual machine\n",
        "msLocalFileList = [dirExperimentName + '/' + s for s in msFileList]\n",
        "print(msLocalFileList)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "J-gESm3q0nNJ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Visualize a couple of frames here for sanity check\n",
        "clip = VideoFileClip(msLocalFileList[0])\n",
        "clip.save_frame(dirExperimentName + '/' + 'frame.png')\n",
        "\n",
        "img=mpl.image.imread(dirExperimentName + '/' + 'frame.png')\n",
        "imgplot = plt.imshow(img); plt.title('Original size')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QbGheAESBI_M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Downsample the videos"
      ]
    },
    {
      "metadata": {
        "id": "m1bL62Ndcvj8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for video in msLocalFileList:\n",
        "  clip = VideoFileClip(video)\n",
        "  resized_clip = clip.resize(1/spatial_downsampling)\n",
        "  os.remove(video)\n",
        "  resized_clip.write_videofile(video,codec='rawvideo')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TlLNRHJRoB_e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# You can use this cell to inspect the downsample video\n",
        "preview_video = False\n",
        "if preview_video:\n",
        "  clip = VideoFileClip(msVideoFilePath) # Play the first video\n",
        "  ipython_display(clip)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EgR-7Sk0Y1w9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Make sure the video has been resized\n",
        "clip = VideoFileClip(msLocalFileList[0])\n",
        "clip.save_frame(dirExperimentName + '/' + 'downsampled_frame.png')\n",
        "\n",
        "img=mpl.image.imread(dirExperimentName + '/' + 'downsampled_frame.png')\n",
        "imgplot = plt.imshow(img); plt.title('Downsampled size')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OvsbmgEANi5i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fnames = msLocalFileList"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VsAQa3GGXGIQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#%% start a cluster for parallel processing (if a cluster already exists it will be closed and a new session will be opened)\n",
        "if 'dview' in locals():\n",
        "    cm.stop_server(dview=dview)\n",
        "c, dview, n_processes = cm.cluster.setup_cluster(\n",
        "    backend='local', n_processes=None, single_thread=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FEBgZ3w7YP1A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Set parameters for motion correction\n",
        "Ideally, optimize these for your datasets then stick to these values"
      ]
    },
    {
      "metadata": {
        "id": "H9zqoGE6XdWg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# dataset dependent parameters\n",
        "frate = 30                       # movie frame rate\n",
        "decay_time = 0.4                 # length of a typical transient in seconds\n",
        "\n",
        "# motion correction parameters\n",
        "motion_correct = True    # flag for performing motion correction\n",
        "pw_rigid = False         # flag for performing piecewise-rigid motion correction (otherwise just rigid)\n",
        "gSig_filt = (3, 3)       # size of high pass spatial filtering, used in 1p data\n",
        "max_shifts = (5, 5)      # maximum allowed rigid shift\n",
        "strides = (48, 48)       # start a new patch for pw-rigid motion correction every x pixels\n",
        "overlaps = (24, 24)      # overlap between patches (size of patch strides+overlaps)\n",
        "max_deviation_rigid = 3  # maximum deviation allowed for patch with respect to rigid shifts\n",
        "border_nan = 'copy'      # replicate values along the boundaries\n",
        "use_cuda = True         # Set to True in order to use GPU\n",
        "only_init_patch = True\n",
        "memory_fact = 0.8\n",
        "\n",
        "mc_dict = {\n",
        "    #'fnames': fnames,\n",
        "    'fr': frate,\n",
        "    'niter_rig': 1,\n",
        "    'splits_rig': 20,  # for parallelization split the movies in  num_splits chuncks across time\n",
        "    # if none all the splits are processed and the movie is saved\n",
        "    'num_splits_to_process_rig': None, # intervals at which patches are laid out for motion correction            \n",
        "    'decay_time': decay_time,\n",
        "    'pw_rigid': pw_rigid,\n",
        "    'max_shifts': max_shifts,\n",
        "    'gSig_filt': gSig_filt,\n",
        "    'strides': strides,\n",
        "    'overlaps': overlaps,\n",
        "    'max_deviation_rigid': max_deviation_rigid,\n",
        "    'border_nan': border_nan,\n",
        "    'use_cuda' : use_cuda,\n",
        "    'only_init_patch' : only_init_patch,\n",
        "    'memory_fact': memory_fact\n",
        "}\n",
        "\n",
        "opts = params.CNMFParams(params_dict=mc_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w2T14jMHB9pL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Perform motion correction (might take a while)"
      ]
    },
    {
      "metadata": {
        "id": "rFevZmmB0P9J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "start = time.time() # This is to keep track of how long the analysis is running\n",
        "if motion_correct:\n",
        "    # do motion correction rigid\n",
        "    mc = MotionCorrect(fnames, dview=dview, **opts.get_group('motion'))\n",
        "    mc.motion_correct(save_movie=True)\n",
        "    fname_mc = mc.fname_tot_els if pw_rigid else mc.fname_tot_rig\n",
        "    \n",
        "end = time.time()\n",
        "\n",
        "print(end - start)\n",
        "print('Motion correction has been done!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dvKKhbtZLoll",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Plot the motion corrected template and associated shifts"
      ]
    },
    {
      "metadata": {
        "id": "6ARRTK-1DdVr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "if motion_correct and not pw_rigid:\n",
        "  plt.figure(figsize=(10,20))\n",
        "  plt.subplot(2, 1, 1); plt.imshow(mc.total_template_rig);  # % plot template\n",
        "  plt.subplot(2, 1, 2); plt.plot(mc.shifts_rig)  # % plot rigid shifts\n",
        "  plt.legend(['x shifts', 'y shifts'])\n",
        "  plt.xlabel('frames')\n",
        "  plt.ylabel('pixels')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8xQACBrn2L2s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Map the motion corrected video to memory"
      ]
    },
    {
      "metadata": {
        "id": "EE52jma-fw5W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if motion_correct:  \n",
        "    if pw_rigid:\n",
        "        bord_px = np.ceil(np.maximum(np.max(np.abs(mc.x_shifts_els)),\n",
        "                                     np.max(np.abs(mc.y_shifts_els)))).astype(np.int)\n",
        "    else:\n",
        "        bord_px = np.ceil(np.max(np.abs(mc.shifts_rig))).astype(np.int)\n",
        "\n",
        "    bord_px = 0 if border_nan is 'copy' else bord_px\n",
        "    fname_new = cm.save_memmap(fname_mc, base_name='memmap_', order='C',\n",
        "                               border_to_0=bord_px)\n",
        "    \n",
        "else:  # if no motion correction just memory map the file\n",
        "    fname_new = cm.save_memmap(fnames, base_name='memmap_',\n",
        "                               order='C', border_to_0=0, dview=dview)\n",
        "    \n",
        "print('Motion corrected video has been mapped to memory')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_8T8mgrMQG-a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load memory mappable file\n",
        "Yr, dims, T = cm.load_memmap(fname_new)\n",
        "images = Yr.T.reshape((T,) + dims, order='F')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WZMG8YVDpuhJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#%% restart cluster to clean up memory\n",
        "cm.stop_server(dview=dview)\n",
        "c, dview, n_processes = cm.cluster.setup_cluster(\n",
        "    backend='local', n_processes=None, single_thread=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uRbJR1LnVsOZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Perform a projection of correlated pixels (and associated signal-to-noise ratio) in motion corrected video\n",
        "This is important to assess the amounts of local correlations and peak-to-noise ratio as well as seed/initialize CNMFe"
      ]
    },
    {
      "metadata": {
        "id": "G2nYOibjxfnN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Compute some summary images (correlation and peak to noise) while downsampling temporally 5x to speedup the process and avoid memory overflow\n",
        "cn_filter, pnr = cm.summary_images.correlation_pnr(images[::5], gSig=3, swap_dim=False) # change swap dim if output looks weird, it is a problem with tiffile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QrIK50l4xj0N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Plot the results of the correlation/PNR projection\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.subplot(2, 2, 1); plt.imshow(cn_filter); plt.colorbar(); plt.title('Correlation projection')\n",
        "plt.subplot(2, 2, 2); plt.imshow(pnr); plt.colorbar(); plt.title('PNR')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OoHBvCL1xaRN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Parameters for source extraction and deconvolution\n",
        "p = 1               # order of the autoregressive system\n",
        "K = None            # upper bound on number of components per patch, in general None\n",
        "gSig = (3, 3)       # gaussian width of a 2D gaussian kernel, which approximates a neuron\n",
        "gSiz = (15, 15)     # average diameter of a neuron, in general 4*gSig+1\n",
        "Ain = None          # possibility to seed with predetermined binary masks\n",
        "merge_thr = .65     # merging threshold, max correlation allowed\n",
        "rf = 40             # half-size of the patches in pixels. e.g., if rf=40, patches are 80x80\n",
        "stride_cnmf = 20    # amount of overlap between the patches in pixels\n",
        "#                     (keep it at least large as gSiz, i.e 4 times the neuron size gSig)\n",
        "tsub = 1            # downsampling factor in time for initialization,\n",
        "#                     increase if you have memory problems\n",
        "ssub = 1            # downsampling factor in space for initialization,\n",
        "#                     increase if you have memory problems\n",
        "#                     you can pass them here as boolean vectors\n",
        "low_rank_background = None  # None leaves background of each patch intact,\n",
        "#                     True performs global low-rank approximation if gnb>0\n",
        "gnb = 1             # number of background components (rank) if positive,\n",
        "#                     else exact ring model with following settings\n",
        "#                         gnb= 0: Return background as b and W\n",
        "#                         gnb=-1: Return full rank background B\n",
        "#                         gnb<-1: Don't return background\n",
        "nb_patch = 0        # number of background components (rank) per patch if gnb>0,\n",
        "#                     else it is set automatically\n",
        "min_corr = .8      # min peak value from correlation image\n",
        "min_pnr = 8        # min peak to noise ration from PNR image\n",
        "ssub_B = 2          # additional downsampling factor in space for background\n",
        "ring_size_factor = 1.4  # radius of ring is gSiz*ring_size_factor\n",
        "memory_fact = 0.8 # How much memory to allocate. 1 works for 16Gb, so 0.8 show be optimized for 12Gb.\n",
        "\n",
        "opts.change_params(params_dict={'method_init': 'corr_pnr',  # use this for 1 photon\n",
        "                                'K': K,\n",
        "                                'gSig': gSig,\n",
        "                                'gSiz': gSiz,\n",
        "                                'merge_thr': merge_thr,\n",
        "                                'p': p,\n",
        "                                'tsub': tsub,\n",
        "                                'ssub': ssub,\n",
        "                                'rf': rf,\n",
        "                                'stride': stride_cnmf,\n",
        "                                'only_init': True,    # set it to True to run CNMF-E\n",
        "                                'nb': gnb,\n",
        "                                'nb_patch': nb_patch,\n",
        "                                'method_deconvolution': 'oasis',       # could use 'cvxpy' alternatively\n",
        "                                'low_rank_background': low_rank_background,\n",
        "                                'update_background_components': True,  # sometimes setting to False improve the results\n",
        "                                'min_corr': min_corr,\n",
        "                                'min_pnr': min_pnr,\n",
        "                                'normalize_init': False,               # just leave as is\n",
        "                                'center_psf': True,                    # leave as is for 1 photon\n",
        "                                'ssub_B': ssub_B,\n",
        "                                'memory_fact': memory_fact,\n",
        "                                'ring_size_factor': ring_size_factor,\n",
        "                                'del_duplicates': True,                # whether to remove duplicates from initialization\n",
        "                                'border_pix': bord_px})                # number of pixels to not consider in the borders)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0qYTxgkIXRy7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Perform CNMFe extraction\n",
        "This will take a while. Coffee time!"
      ]
    },
    {
      "metadata": {
        "id": "eY9rPjLixkdV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "# Perform CNMF\n",
        "cnm = cnmf.CNMF(n_processes=n_processes, dview=dview, Ain=Ain, params=opts)\n",
        "cnm.fit(images)\n",
        "\n",
        "end = time.time()\n",
        "print(end - start)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f0fUUIlVWimm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Evaluate components"
      ]
    },
    {
      "metadata": {
        "id": "M4fIznK_WhOg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#%% COMPONENT EVALUATION\n",
        "# the components are evaluated in three ways:\n",
        "#   a) the shape of each component must be correlated with the data\n",
        "#   b) a minimum peak SNR is required over the length of a transient\n",
        "#   c) each shape passes a CNN based classifier\n",
        "\n",
        "min_SNR = 3            # adaptive way to set threshold on the transient size\n",
        "r_values_min = 0.85    # threshold on space consistency (if you lower more components\n",
        "#                        will be accepted, potentially with worst quality)\n",
        "cnm.params.set('quality', {'min_SNR': min_SNR,\n",
        "                           'rval_thr': r_values_min,\n",
        "                           'use_cnn': False})\n",
        "cnm.estimates.evaluate_components(images, cnm.params, dview=dview)\n",
        "\n",
        "print(' ***** ')\n",
        "print('Number of total components: ', len(cnm.estimates.C))\n",
        "print('Number of accepted components: ', len(cnm.estimates.idx_components))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_amkY5qGYfuh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Plot the results for inspection"
      ]
    },
    {
      "metadata": {
        "id": "kQOPgvb_SlsH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "#How many neurons to plot\n",
        "neuronsToPlot = 20\n",
        "\n",
        "DeconvTraces = cnm.estimates.S\n",
        "RawTraces = cnm.estimates.C\n",
        "SFP = cnm.estimates.A\n",
        "SFP_dims = list(dims)\n",
        "SFP_dims.append(SFP.shape[1]) \n",
        "print('Spatial foootprints dimensions (height x width x neurons): ' + str(SFP_dims))\n",
        "\n",
        "numNeurons = SFP_dims[2]\n",
        "\n",
        "SFP = np.reshape(SFP.toarray(), SFP_dims, order='F')\n",
        "\n",
        "maxRawTraces = np.amax(RawTraces)\n",
        "\n",
        "plt.figure(figsize=(30,15))\n",
        "plt.subplot(341);\n",
        "plt.subplot(345); plt.plot(mc.shifts_rig); plt.title('Motion corrected shifts')\n",
        "plt.subplot(3,4,9);\n",
        "plt.subplot(3,4,2); plt.imshow(cn_filter); plt.colorbar(); plt.title('Correlation projection')\n",
        "plt.subplot(3,4,6); plt.imshow(pnr); plt.colorbar(); plt.title('PNR')\n",
        "plt.subplot(3,4,10); plt.imshow(np.amax(SFP,axis=2)); plt.colorbar(); plt.title('Spatial footprints')\n",
        "\n",
        "plt.subplot(2,2,2); plt.figure; plt.title('Example traces (first 50 cells)')\n",
        "plot_gain = 10 # To change the value gain of traces\n",
        "if numNeurons >= neuronsToPlot:\n",
        "  for i in range(neuronsToPlot):\n",
        "    if i == 0:\n",
        "      plt.plot(RawTraces[i,:],'k')\n",
        "    else:\n",
        "      trace = RawTraces[i,:] + maxRawTraces*i/plot_gain\n",
        "      plt.plot(trace,'k')\n",
        "else:\n",
        "  for i in range(numNeurons):\n",
        "    if i == 0:\n",
        "      plt.plot(RawTraces[i,:],'k')\n",
        "    else:\n",
        "      trace = RawTraces[i,:] + maxRawTraces*i/plot_gain\n",
        "      plt.plot(trace,'k')\n",
        "\n",
        "plt.subplot(2,2,4); plt.figure; plt.title('Deconvolved traces (first 50 cells)')\n",
        "plot_gain = 20 # To change the value gain of traces\n",
        "if numNeurons >= neuronsToPlot:\n",
        "  for i in range(neuronsToPlot):\n",
        "    if i == 0:\n",
        "      plt.plot(DeconvTraces[i,:],'k')\n",
        "    else:\n",
        "      trace = DeconvTraces[i,:] + maxRawTraces*i/plot_gain\n",
        "      plt.plot(trace,'k')\n",
        "else:\n",
        "  for i in range(numNeurons):\n",
        "    if i == 0:\n",
        "      plt.plot(DeconvTraces[i,:],'k')\n",
        "    else:\n",
        "      trace = DeconvTraces[i,:] + maxRawTraces*i/plot_gain\n",
        "      plt.plot(trace,'k')      \n",
        "\n",
        "# Save summary figure\n",
        "plt.savefig(dirExperimentName + '/' + 'summary_figure.svg', edgecolor='w', format='svg', transparent=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yRHH0VXHxTjV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Register the timestamps for analysis"
      ]
    },
    {
      "metadata": {
        "id": "2OQO2cgtxRso",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Open timestamps.dat here\n",
        "try:\n",
        "  metadata, res = dbx.files_download(path_to_analyze + '/' + 'timestamp.dat')\n",
        "  f = open('timestamp.dat','wb')\n",
        "  f.write(res.content)\n",
        "  f.close\n",
        "except FileExistsError:\n",
        "  print('Error: timestamp.dat could not be found')\n",
        "\n",
        "with open('timestamp.dat') as f:\n",
        "  camNum, frameNum, sysClock, buffer = np.loadtxt(f, dtype='float', comments='#', skiprows=1, unpack = True)\n",
        "  \n",
        "cameraMatched = False\n",
        "for j in range(int(max(camNum))+1):\n",
        "  if sum(camNum==j) != 0:\n",
        "    camFrameList, = np.where(camNum == j)\n",
        "    camLastFrame = camFrameList[-1]\n",
        "    LastFrame = frameNum[camLastFrame]\n",
        "    if (sum(camNum==j) == len(RawTraces[1])) and (LastFrame == len(RawTraces[1])):\n",
        "      camNumber = j\n",
        "      mstime_idx = np.where(camNum == j)\n",
        "      mstime=sysClock[mstime_idx]\n",
        "      mstime[0] = 0\n",
        "      maxBufferUsed = max(buffer[mstime_idx])\n",
        "      cameraMatched = True\n",
        "      \n",
        "if cameraMatched is not True:\n",
        "  print('Problem matching up timestamps for ' + experimentName)\n",
        "else:\n",
        "  print('Successfully registered timestamps for ' + experimentName)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_x6AwkCAeSBP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Stop counter and register analysis time\n",
        "analysis_end = time.time()\n",
        "\n",
        "analysis_duration = analysis_end - analysis_start\n",
        "\n",
        "print('Done analyzing. This took a total ' + str(analysis_duration) + ' s')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AffqpHnZXAmE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Save the results in HDF5 format"
      ]
    },
    {
      "metadata": {
        "id": "pAz-IKFnglm5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if save_hdf5: \n",
        "  cnm.save('dirExperimentName' + 'analysis_results.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NvKU553YMJTh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Save the results in Matlab format"
      ]
    },
    {
      "metadata": {
        "id": "j5InkgAwMMhD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if save_mat:\n",
        "  from scipy.io import savemat\n",
        "  \n",
        "  results_dict = {\n",
        "                'dirName': path_to_analyze,\n",
        "                'numFiles': len(msFileList),\n",
        "                'framesNum': len(RawTraces[1]),\n",
        "                'maxFramesPerFile': 1000,\n",
        "                'height': dims[0],\n",
        "                'width': dims[1],\n",
        "                'Experiment': experimentName,\n",
        "                'ExperimentTimestamp': experiment_timestamp,\n",
        "                'camNumber': 0,\n",
        "                'time': mstime,\n",
        "                'analysis_time': analysis_time,\n",
        "                'ds': spatial_downsampling,\n",
        "                'shifts': mc.shifts_rig,\n",
        "                'meanFrame': [], #TO DO\n",
        "                'Centroids': [], #TO DO\n",
        "                'CorrProj': cn_filter,\n",
        "                'PeakToNoiseProj': pnr,\n",
        "                'FiltTraces': [], #TO DO\n",
        "                'RawTraces': RawTraces.conj().transpose(), #swap time x neurons dimensions\n",
        "                'SFP': SFP,\n",
        "                'numNeurons': SFP_dims[2],\n",
        "                'analysis_duration': analysis_duration\n",
        "                }\n",
        "\n",
        "  SFPperm = np.transpose(SFP,[2,0,1])\n",
        "  sio.savemat(dirExperimentName + '/SFP.mat', {'SFP': SFPperm})\n",
        "  sio.savemat(dirExperimentName + '/ms.mat', {'ms': results_dict})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PNKq4sts58Am",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Transfer analysis to Dropbox"
      ]
    },
    {
      "metadata": {
        "id": "IlpbHVAxUXPG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open(dirExperimentName + '/ms.mat', 'rb') as f:\n",
        "  dbx.files_upload(f.read(), path_to_results + analysis_time + '/' + experimentName + '/ms.mat',mode=dropbox.files.WriteMode(\"overwrite\"))\n",
        "  \n",
        "with open(dirExperimentName + '/SFP.mat', 'rb') as f:\n",
        "  dbx.files_upload(f.read(), path_to_results + analysis_time + '/' + experimentName + '/SFP.mat',mode=dropbox.files.WriteMode(\"overwrite\"))\n",
        "\n",
        "with open(dirExperimentName + '/summary_figure.png', 'rb') as f:\n",
        "  dbx.files_upload(f.read(), path_to_results + analysis_time + '/' + experimentName + '/summary_figure.png',mode=dropbox.files.WriteMode(\"overwrite\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oDw-nYiTbBUK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Make sure the file is up there (in the cloud)\n",
        "response = dbx.files_list_folder(path_to_results + analysis_time + '/' + experimentName)\n",
        "\n",
        "print('These files have successfully been uploaded:')\n",
        "for file in response.entries:\n",
        "  print(file.name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "70bmP_6gf9rk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#%% STOP CLUSTER and clean up log files\n",
        "cm.stop_server(dview=dview)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mb1_GszF7B5u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Analyze behavior videos**\n",
        "This section is to analyse the behavior video present in your experiment folder. Briefly, you will download the videos on your Colab virtual machine, concatenate the video (and optionally crop them), and finally process them with DeepLabCut to perform pose estimation. The output can be saved in a hdf5 format, a Matlab file or simply a csv file. Results are transfered back to your Dropbox/Google drive "
      ]
    },
    {
      "metadata": {
        "id": "UDc9fqHx_Vrp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install deeplabcut\n",
        "import os\n",
        "os.environ[\"DLClight\"]=\"True\"\n",
        "os.environ[\"Colab\"]=\"True\"\n",
        "\n",
        "import deeplabcut"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z6DpLJxABM8x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Run this cell if you have any issue with pillow/register_extensions when plotting images\n",
        "!pip install Pillow==4.0.0\n",
        "\n",
        "from PIL import Image\n",
        "def register_extension(id, extension): Image.EXTENSION[extension.lower()] = id.upper()\n",
        "Image.register_extension = register_extension\n",
        "def register_extensions(id, extensions): \n",
        "  for extension in extensions: register_extension(id, extension)\n",
        "Image.register_extensions = register_extensions\n",
        "\n",
        "!pip install ruamel.yaml==0.15\n",
        "!pip install pandas==0.21.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7xmDFQXK76Yr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "metadata, res = dbx.files_download(path_to_DLC_model)\n",
        "with open('DeepLabCut.zip','wb') as f:\n",
        "  f.write(res.content)\n",
        "  \n",
        "zip_ref = zipfile.ZipFile('DeepLabCut.zip', 'r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b9PIiODR-LU3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path_config_file = '/content/DeepLabCut/Guillaume_trained_model/config.yaml'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NCQ81qWJ7s4R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sessionFilesResponse = dbx.files_list_folder(path_to_analyze)\n",
        "filesList = []\n",
        "behavFileList = []\n",
        "\n",
        "for file in sessionFilesResponse.entries:\n",
        "  filesList.append(file.name)\n",
        "\n",
        "for i in filesList[:]:\n",
        "  if i.startswith('behav') and i.endswith('.avi'):\n",
        "    behavFileList.append(i)\n",
        "    \n",
        "behavFileList = sorted(behavFileList, key=lambda x: int(re.sub('[behavCam.avi]','', x)))\n",
        "\n",
        "print('Miniscope files in folder:')\n",
        "print(behavFileList)\n",
        "\n",
        "if len(behavFileList) == 0:\n",
        "  print(\"No behavior avi files found\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gCV9Fl7f8jTQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('Downloading behavior videos from Dropbox.....')\n",
        "for file in behavFileList:\n",
        "    f = open(dirExperimentName + '/' + file,\"wb+\") \n",
        "    metadata, res = dbx.files_download(path_to_analyze + '/' + file)\n",
        "    f.write(res.content)\n",
        "    f.close()\n",
        "    print(path_to_analyze + '/' + file + '.....done!')\n",
        "print('Done downloading behavior videos!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SCAS3TOy8uS_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create a list of files downloaded on the Colab virtual machine\n",
        "behavLocalFileList = [dirExperimentName + '/' + s for s in behavFileList]\n",
        "print(behavLocalFileList)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BngpGSyP8ww2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create behavVideo.avi here\n",
        "clips=[]\n",
        "for video in behavLocalFileList:\n",
        "  if video == behavLocalFileList[0]:\n",
        "    final_clip = VideoFileClip(video)\n",
        "  else:\n",
        "    clip = VideoFileClip(video)\n",
        "    final_clip = concatenate_videoclips([final_clip, clip]) \n",
        "\n",
        "behavVideoFilePath = dirExperimentName + '/' + 'behavVideo.avi'\n",
        "final_clip.write_videofile(behavVideoFilePath,codec='rawvideo')  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6zU-D9uZUIQ4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "# Visualize a frame for potential cropping\n",
        "clip = VideoFileClip(behavVideoFilePath)\n",
        "print('Video dimensions (witdh x height):')\n",
        "behav_dims = clip.size\n",
        "print(behav_dims)\n",
        "\n",
        "clip.save_frame(dirExperimentName + '/' + 'behav_frame.png')\n",
        "\n",
        "img=mpl.image.imread(dirExperimentName + '/' + 'behav_frame.png')\n",
        "imgplot = plt.imshow(img); plt.title('Original size')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NixopuEVUHjO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "is_crop = False\n",
        "if is_crop:\n",
        "  clip = VideoFileClip(behavVideoFilePath)\n",
        "  cropped_clip = clip.crop(x1=0, y1=50, x2=638, y2=120)\n",
        "  cropped_clip.write_videofile(behavVideoFilePath + '_CROPPED.avi',codec='rawvideo')\n",
        "  behavVideoFilePath = behavVideoFilePath + '_CROPPED.avi'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F-4n8ABmV1Zt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if is_crop:\n",
        "  # Visualize the croped video\n",
        "  clip = VideoFileClip(behavVideoFilePath)\n",
        "  print(clip.size)\n",
        "  clip.save_frame(dirExperimentName + '/' + 'cropped_behav_frame.png')\n",
        "\n",
        "  img=mpl.image.imread(dirExperimentName + '/' + 'cropped_behav_frame.png')\n",
        "  imgplot = plt.imshow(img); plt.title('Cropped video')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MFElnSz_eHUY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "behavVideoFilePath = [behavVideoFilePath]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kdRqsYCi94cF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "deeplabcut.analyze_videos(path_config_file,behavVideoFilePath, save_as_csv=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wzsny7-ZggfF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Find the results in the h5file\n",
        "for file in os.listdir(dirExperimentName):\n",
        "    if file.endswith('.csv'):\n",
        "      behavResultsCSVFile = os.path.join(dirExperimentName, file)\n",
        "      \n",
        "with open(behavResultsCSVFile) as f:\n",
        "    reader = csv.reader(f)\n",
        "    scorer = next(reader);\n",
        "    bodyparts = next(reader);\n",
        "    coordinates = next(reader);\n",
        "\n",
        "header = []\n",
        "for i in range(len(bodyparts)):\n",
        "  header.append(bodyparts[i] + '_' + coordinates[i]);\n",
        "  \n",
        "with open(behavResultsCSVFile) as f:  \n",
        "  data = np.loadtxt(f, dtype='float', delimiter=',', comments='#', skiprows=3, unpack = True)\n",
        "\n",
        "# Delete the first column that does not contain relevant information\n",
        "header.pop(0)\n",
        "data = np.delete(data, 0, axis=0)\n",
        "\n",
        "\n",
        "position = dict(zip(header,data))  \n",
        "  \n",
        "# Get number of frames\n",
        "dims_behav = np.shape(data)\n",
        "behavNumFrames = dims_behav[1]\n",
        "print('Behavior video has ' + str(behavNumFrames) + ' frames')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LX9HvMKZT12b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Open timestamps.dat here\n",
        "try:\n",
        "  metadata, res = dbx.files_download(path_to_analyze + '/' + 'timestamp.dat')\n",
        "  f = open('timestamp.dat','wb')\n",
        "  f.write(res.content)\n",
        "  f.close\n",
        "except FileExistsError:\n",
        "  print('Error: timestamp.dat could not be found')\n",
        "\n",
        "with open('timestamp.dat') as f:\n",
        "  \n",
        "  camNum, frameNum, sysClock, buffer = np.loadtxt(f, dtype='float', comments='#', skiprows=1, unpack = True)\n",
        "  \n",
        "cameraMatched = False\n",
        "for j in range(int(max(camNum))+1):\n",
        "  if sum(camNum==j) != 0:\n",
        "    camFrameList, = np.where(camNum == j)\n",
        "    camLastFrame = camFrameList[-1]\n",
        "    LastFrame = frameNum[camLastFrame]\n",
        "    if (sum(camNum==j) == behavNumFrames) and (LastFrame == behavNumFrames):\n",
        "      camNumber = j\n",
        "      behavtime_idx = np.where(camNum == j)\n",
        "      behavtime=sysClock[behavtime_idx]\n",
        "      behavtime[0] = 0\n",
        "      maxBufferUsed = max(buffer[behavtime_idx])\n",
        "      cameraMatched = True\n",
        "      \n",
        "if cameraMatched is not True:\n",
        "  print('Problem matching up timestamps for ' + experimentName)\n",
        "else:\n",
        "  print('Successfully registered timestamps for ' + experimentName)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FUenw-vfS0ov",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if save_mat:\n",
        "  from scipy.io import savemat\n",
        "  \n",
        "  results_dict = {\n",
        "                'dirName': path_to_analyze,\n",
        "                'numFiles': len(behavFileList),\n",
        "                'framesNum': behavNumFrames,\n",
        "                'maxFramesPerFile': 1000,\n",
        "                'height': behav_dims[1],\n",
        "                'width': behav_dims[0],\n",
        "                'Experiment': experimentName,\n",
        "                'ExperimentTimestamp': experiment_timestamp,\n",
        "                'camNumber': camNumber,\n",
        "                'time': behavtime,\n",
        "                'analysis_time': analysis_time,\n",
        "                'background': [], #TO DO\n",
        "                'position': position\n",
        "                }\n",
        "\n",
        "  sio.savemat(dirExperimentName + '/behav.mat', {'behav': results_dict})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g5U5xfVXSU_E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This generates a labeled video. You can use it to validate the inference\n",
        "deeplabcut.create_labeled_video(path_config_file,behavVideoFilePath)\n",
        "\n",
        "for file in os.listdir(dirExperimentName):\n",
        "    if file.endswith('.mp4'):\n",
        "      labeled_video = os.path.join(dirExperimentName, file)\n",
        "      print(labeled_video)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YBWiUrZVTpf0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open(dirExperimentName + '/behav.mat', 'rb') as f:\n",
        "  dbx.files_upload(f.read(), path_to_results + analysis_time + '/' + experimentName + '/behav.mat',mode=dropbox.files.WriteMode(\"overwrite\"))\n",
        "  \n",
        "with open(labeled_video, 'rb') as f:\n",
        "  dbx.files_upload(f.read(), path_to_results + analysis_time + '/' + experimentName + '/labeled_video.mp4',mode=dropbox.files.WriteMode(\"overwrite\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QyrZNq5RTqHN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Make sure the file is up there (in the cloud)\n",
        "response = dbx.files_list_folder(path_to_results + analysis_time + '/' + experimentName)\n",
        "\n",
        "print('These files have successfully been uploaded:')\n",
        "for file in response.entries:\n",
        "  print(file.name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "borxuRH3nmK4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Done analyzing!\n",
        "From there, you can program an alarm (eg email, text) to notify you that the analysis has been completed."
      ]
    },
    {
      "metadata": {
        "id": "tm9_DEjEnxS5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "msg = 'Your analysis ' + experimentName + ' has just finished!'\n",
        "\n",
        "server = smtplib.SMTP('smtp.gmail.com', 587)\n",
        "server.starttls()\n",
        "server.login(alert_email, alert_email_password)\n",
        " \n",
        "msg = \"COLAB WORK FINISH ALERT!\"\n",
        "server.sendmail(alert_email, alert_email, msg)\n",
        "server.quit()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}